{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grounding DINO Internals: Understanding pred_logits\n",
        "\n",
        "This notebook walks through how Grounding DINO processes images and text to produce predictions.\n",
        "\n",
        "We'll explore:\n",
        "1. Text tokenization and encoding\n",
        "2. Visual feature extraction  \n",
        "3. Contrastive similarity computation (pred_logits)\n",
        "4. Token-to-class mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "sys.path.insert(0, str(project_root / 'GroundingDINO'))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Load the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from groundingdino.util.slconfig import SLConfig\n",
        "from groundingdino.models import build_model\n",
        "from groundingdino.util.utils import clean_state_dict\n",
        "\n",
        "# Load config\n",
        "config_path = project_root / 'GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
        "checkpoint_path = project_root / 'data/models/pretrained/groundingdino_swint_ogc.pth'\n",
        "\n",
        "args = SLConfig.fromfile(str(config_path))\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = build_model(args)\n",
        "checkpoint = torch.load(str(checkpoint_path), map_location='cpu')\n",
        "model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
        "model = model.to(args.device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {args.device}\")\n",
        "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Understand the Text Pipeline\n",
        "\n",
        "Grounding DINO uses BERT to encode text. Let's see how class names become token embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Our example classes\n",
        "class_names = ['dog', 'cat', 'car']\n",
        "\n",
        "# Grounding DINO formats classes as: \"class1 . class2 . class3.\"\n",
        "caption = \" . \".join(class_names) + \".\"\n",
        "print(f\"Caption: '{caption}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the tokenizer\n",
        "tokenizer = model.tokenizer\n",
        "\n",
        "# Tokenize the caption\n",
        "tokenized = tokenizer(\n",
        "    caption,\n",
        "    padding='max_length',\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids = tokenized['input_ids'][0]\n",
        "attention_mask = tokenized['attention_mask'][0]\n",
        "\n",
        "print(f\"Input IDs shape: {input_ids.shape}\")\n",
        "print(f\"Attention mask shape: {attention_mask.shape}\")\n",
        "print(f\"\\nFirst 15 tokens:\")\n",
        "\n",
        "# Decode tokens to see what they are\n",
        "for i in range(15):\n",
        "    token_id = input_ids[i].item()\n",
        "    token = tokenizer.decode([token_id])\n",
        "    mask = attention_mask[i].item()\n",
        "    print(f\"  Position {i:2d}: ID={token_id:5d}, Token='{token:10s}', Mask={mask}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use official utility to get token spans for each class\n",
        "from groundingdino.util.vl_utils import build_captions_and_token_span, create_positive_map_from_span\n",
        "\n",
        "caption_formatted, cat2tokenspan = build_captions_and_token_span(class_names, force_lowercase=False)\n",
        "\n",
        "print(f\"Formatted caption: '{caption_formatted}'\")\n",
        "print(f\"\\nCharacter spans per class:\")\n",
        "for class_name, spans in cat2tokenspan.items():\n",
        "    print(f\"  '{class_name}': characters {spans}\")\n",
        "\n",
        "# Create positive_map: which tokens belong to which class\n",
        "tokenized_for_map = tokenizer(caption_formatted, padding='longest', return_tensors='pt')\n",
        "token_span_per_class = [cat2tokenspan.get(name, []) for name in class_names]\n",
        "\n",
        "positive_map = create_positive_map_from_span(\n",
        "    tokenized_for_map,\n",
        "    token_span_per_class,\n",
        "    max_text_len=256\n",
        ")  # Shape: [num_classes, max_text_len]\n",
        "\n",
        "print(f\"\\nPositive map shape: {positive_map.shape}\")\n",
        "print(f\"\\nToken positions for each class:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    token_positions = (positive_map[i] > 0).nonzero(as_tuple=True)[0].tolist()\n",
        "    print(f\"  Class {i} '{class_name}': tokens at positions {token_positions}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Prepare an Image and Run Forward Pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import groundingdino.datasets.transforms as T\n",
        "\n",
        "# Create a sample image (or load one if available)\n",
        "sample_images = list((project_root / 'data').rglob('*.jpg'))[:1]\n",
        "if not sample_images:\n",
        "    sample_images = list((project_root / 'data').rglob('*.png'))[:1]\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.RandomResize([800], max_size=1333),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "if sample_images:\n",
        "    image_path = sample_images[0]\n",
        "    print(f\"Using image: {image_path}\")\n",
        "    image_source = np.array(Image.open(image_path).convert('RGB'))\n",
        "else:\n",
        "    print(\"No sample image found, creating a random 640x480 image\")\n",
        "    image_source = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
        "\n",
        "image_pil = Image.fromarray(image_source)\n",
        "image_tensor, _ = transform(image_pil, None)\n",
        "\n",
        "print(f\"Original image shape: {image_source.shape}\")\n",
        "print(f\"Preprocessed tensor shape: {image_tensor.shape}\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(image_source)\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = args.device\n",
        "\n",
        "# Prepare batch\n",
        "images = image_tensor.unsqueeze(0).to(device)  # [1, 3, H, W]\n",
        "captions = [caption_formatted]\n",
        "\n",
        "print(f\"Input images shape: {images.shape}\")\n",
        "print(f\"Caption: {captions}\")\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    outputs = model(samples=images, captions=captions)\n",
        "\n",
        "print(f\"\\nOutput keys: {outputs.keys()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Understand pred_logits (The Key Step!)\n",
        "\n",
        "pred_logits contains the **dot product similarity** between:\n",
        "- Visual queries (900 learned queries that attend to image regions)\n",
        "- Text tokens (256 positions from BERT encoding)\n",
        "\n",
        "This is NOT class probabilities yet!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect the outputs\n",
        "pred_logits = outputs['pred_logits']  # [B, num_queries, num_tokens]\n",
        "pred_boxes = outputs['pred_boxes']    # [B, num_queries, 4]\n",
        "\n",
        "print(f\"pred_logits shape: {pred_logits.shape}\")\n",
        "print(f\"pred_boxes shape: {pred_boxes.shape}\")\n",
        "print(f\"\\nNumber of queries: {pred_logits.shape[1]}\")\n",
        "print(f\"Number of text tokens: {pred_logits.shape[2]}\")\n",
        "\n",
        "# Look at raw logits statistics\n",
        "logits = pred_logits[0]  # [num_queries, num_tokens]\n",
        "\n",
        "print(f\"\\nRaw logits statistics:\")\n",
        "print(f\"  Min: {logits.min().item():.2f}\")\n",
        "print(f\"  Max: {logits.max().item():.2f}\")\n",
        "print(f\"  Mean: {logits.mean().item():.2f}\")\n",
        "\n",
        "# Check for -inf (padding tokens)\n",
        "num_inf = torch.isinf(logits).sum().item()\n",
        "print(f\"  Number of -inf values: {num_inf} (these are padding tokens)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to probabilities with sigmoid\n",
        "token_probs = logits.sigmoid()  # [num_queries, num_tokens]\n",
        "\n",
        "print(f\"Token probabilities after sigmoid:\")\n",
        "print(f\"  Min: {token_probs.min().item():.6f}\")\n",
        "print(f\"  Max: {token_probs.max().item():.6f}\")\n",
        "print(f\"  Mean: {token_probs.mean().item():.6f}\")\n",
        "\n",
        "# Find the query with highest confidence\n",
        "max_prob_per_query = token_probs.max(dim=1)[0]  # [num_queries]\n",
        "top_query_idx = max_prob_per_query.argmax().item()\n",
        "top_query_confidence = max_prob_per_query[top_query_idx].item()\n",
        "\n",
        "print(f\"\\nQuery with highest confidence: {top_query_idx}\")\n",
        "print(f\"Highest token probability: {top_query_confidence:.4f}\")\n",
        "\n",
        "# Look at this query's token probabilities for class tokens\n",
        "top_query_probs = token_probs[top_query_idx]  # [num_tokens]\n",
        "\n",
        "print(f\"\\nToken probabilities for top query (first 10 tokens):\")\n",
        "for i in range(10):\n",
        "    prob = top_query_probs[i].item()\n",
        "    token_id = tokenized_for_map['input_ids'][0, i].item()\n",
        "    token = tokenizer.decode([token_id])\n",
        "    print(f\"  Position {i}: '{token:10s}' = {prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Map Token Probabilities to Class Scores\n",
        "\n",
        "Now we use positive_map to aggregate token probabilities into class scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positive_map = positive_map.to(device)\n",
        "\n",
        "# Compute class scores for each query\n",
        "num_queries = token_probs.shape[0]\n",
        "num_classes = len(class_names)\n",
        "\n",
        "class_probs = torch.zeros(num_queries, num_classes, device=device)\n",
        "\n",
        "for c in range(num_classes):\n",
        "    # Which tokens belong to this class?\n",
        "    token_mask = positive_map[c] > 0\n",
        "    \n",
        "    if token_mask.sum() > 0:\n",
        "        # Average the token probabilities for this class\n",
        "        class_probs[:, c] = token_probs[:, token_mask].mean(dim=-1)\n",
        "\n",
        "print(f\"Class probabilities shape: {class_probs.shape}\")\n",
        "print(f\"  [num_queries={num_queries}, num_classes={num_classes}]\")\n",
        "\n",
        "# For each query, get the best class and score\n",
        "scores, labels = class_probs.max(dim=-1)  # [num_queries], [num_queries]\n",
        "\n",
        "# Filter by confidence threshold\n",
        "threshold = 0.3\n",
        "keep = scores > threshold\n",
        "\n",
        "print(f\"\\nQueries with confidence > {threshold}: {keep.sum().item()}\")\n",
        "\n",
        "# Show top 10 detections\n",
        "top_indices = scores.argsort(descending=True)[:10]\n",
        "\n",
        "print(f\"\\nTop 10 detections:\")\n",
        "print(f\"{'Query':>6} {'Class':>10} {'Score':>8}\")\n",
        "print(\"-\" * 30)\n",
        "for idx in top_indices:\n",
        "    query_idx = idx.item()\n",
        "    label = labels[query_idx].item()\n",
        "    score = scores[query_idx].item()\n",
        "    class_name = class_names[label]\n",
        "    print(f\"{query_idx:6d} {class_name:>10} {score:8.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The key insight is that **pred_logits is NOT class probabilities**.\n",
        "\n",
        "The full pipeline:\n",
        "\n",
        "```\n",
        "1. Text: \"dog . cat . car.\" → BERT → text_features [1, 256, 768]\n",
        "                                    ↓ projection\n",
        "                              proj_text [1, 256, 256]\n",
        "\n",
        "2. Image → Swin → Transformer Decoder → query_features [1, 900, 256]\n",
        "                                              ↓ projection  \n",
        "                                        proj_visual [1, 900, 256]\n",
        "\n",
        "3. pred_logits = proj_visual @ proj_text.T / temperature\n",
        "   Shape: [1, 900, 256] (similarity between each query and each token)\n",
        "\n",
        "4. token_probs = sigmoid(pred_logits)\n",
        "   Shape: [1, 900, 256] (probabilities in [0, 1])\n",
        "\n",
        "5. class_probs = aggregate(token_probs, positive_map)\n",
        "   Shape: [1, 900, 3] (probability per class)\n",
        "\n",
        "6. Final: filter by threshold, get (boxes, scores, labels)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
